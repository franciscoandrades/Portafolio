{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "attachments": {
                "ibm-cloud.png": {
                    "image/png": "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"
                }
            },
            "cell_type": "markdown",
            "metadata": {},
            "source": "![ibm-cloud.png](attachment:ibm-cloud.png)\n\n## Setup your notebook file stystem on Watson Studio\n\nAll of the notebooks in these courses are written to run locally on your computer running a Jupyter notebook server.  If you wish to run the notebooks in Watson Studio in the IBM Cloud, you will need to add some modifications to each notebook.\n\nWhy?  Because once you import a course notebook and the data files for that notebook into a Watson Studio project, the data files are no longer available to the notebook! \nThis is simply due to the fact that the imported data files are stored in an IBM Cloud Object Storage (COS) bucket.  The notebook does not have access to those objects in the COS bucket.  Thus, if you import a notebook and its data files into a Studio project then try to run it, the notebook will return \"File not found\" errors. \nIn order to make the data files available to your notebook, you will need to run some code in your notebook to: \n\n1 - Access the correct COS bucket <br>\n2 - Read your data file from the bucket into a byte stream object <br>\n3 - Write that byte stream object to the virtual disk of the container running the notebook. "
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "# cos2file - takes an object from Cloud Object Storage and writes it to file on container file system.\n# Uses the IBM project_lib library.\n# See https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/project-lib-python.html\n# Arguments:\n# p: project object defined in project token\n# data_path: the directory to write the file\n# filename: name of the file in COS\n\nimport os\ndef cos2file(p,data_path,filename):\n    data_dir = p.project_context.home + data_path\n    if not os.path.exists(data_dir):\n        os.makedirs(data_dir)\n    open( data_dir + '/' + filename, 'wb').write(p.get_file(filename).read())"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "# Calling cos2file allows to make the data files available to the notebook \ncos2file(project, '/data', 'aavail-target.csv')"
        },
        {
            "attachments": {
                "ibm-cloud.png": {
                    "image/png": "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"
                }
            },
            "cell_type": "markdown",
            "metadata": {},
            "source": "![ibm-cloud.png](attachment:ibm-cloud.png)\n\n# CASE STUDY - Unsupervised Learning\n"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "%%capture\n! pip install -U scikit-learn\n! pip install -U imblearn"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": "import os\nimport time\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.cluster import KMeans, SpectralClustering\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report, f1_score\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.mixture import BayesianGaussianMixture\nfrom sklearn.svm import SVC\nimport imblearn.pipeline as pl\nfrom imblearn.pipeline import make_pipeline\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.over_sampling import SMOTE, SVMSMOTE\n    \n    \nplt.style.use('seaborn')\n%matplotlib inline\n\nDATA_DIR = os.path.join(\"..\",\"data\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Synopsis\n\n  > We are now going to predict customer retention.  There are many models and many transforms to consider.  Use your\n    knowledge of pipelines and functions to ensure that your code makes it easy to compare and iterate over.  \n    \n  > Marketing has asked you to make a report on customer retention.  They would like you to come up with information     that can be used to improve current marketing strategy efforts.  The current plan is for marketing at AAVAiL to\n    collect more features on subscribers the and they would like to use your report as a proof-of-concept in order to     get buyin for this effort.\n  \n## Outline\n\n1. Create a churn prediction baseline model\n2. Use clustering as part of your prediction pipeline\n3. Run and experiment to see if re-sampling techniques improve your model\n\n## Data\n\nHere we load the data as we have already done.\n\n`aavail-target.csv`"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>age</th>\n      <th>subscriber_type</th>\n      <th>num_streams</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>united_states</td>\n      <td>21</td>\n      <td>aavail_premium</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>singapore</td>\n      <td>30</td>\n      <td>aavail_unlimited</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>united_states</td>\n      <td>21</td>\n      <td>aavail_premium</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>united_states</td>\n      <td>20</td>\n      <td>aavail_basic</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>singapore</td>\n      <td>21</td>\n      <td>aavail_premium</td>\n      <td>23</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "         country  age   subscriber_type  num_streams\n0  united_states   21    aavail_premium           23\n1      singapore   30  aavail_unlimited           12\n2  united_states   21    aavail_premium           22\n3  united_states   20      aavail_basic           19\n4      singapore   21    aavail_premium           23"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df = pd.read_csv(os.path.join(DATA_DIR, r\"aavail-target.csv\"))\n\n## pull out the target and remove uneeded columns\n_y = df.pop('is_subscriber')\ny = np.zeros(_y.size)\ny[_y==0] = 1 \ndf.drop(columns=['customer_id', 'customer_name'], inplace=True)\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### QUESTION 1\n\nUsing the train_test_split() function, create a stratified train test split of the data"
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [],
            "source": "## YOUR CODE HERE\nX_train,X_test,y_train,y_test = train_test_split(df,y,test_size = 0.25,stratify = y,random_state = 42)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### QUESTION 2\n\nCreate a baseline model.  We are going to test whether clustering followed by a model improves the results.  Then, we will test whether re-sampling techniques provide improvements.  Use a pipeline or another method, but create a baseline model given the data. Here is the ColumnTransformer we have used before:"
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {},
            "outputs": [],
            "source": "## preprocessing pipeline\nnumeric_features = ['age', 'num_streams']\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())])\n\ncategorical_features = ['country', 'subscriber_type']\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('encod', OrdinalEncoder())])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])"
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "f1_score 0.598\n"
                }
            ],
            "source": "# YOUR CODE HERE (Replace the #<> symbols with your code)\n\n# Create an instance of a binary classifier.\nclf = RandomForestClassifier()\n\n# Create a pipeline that binds the preprocessing transformer and the classifier estimator.\npipe = Pipeline(steps=[('pre', preprocessor),\n                          ('rf', clf)])\n\n# Here we apply a grid search to optimize the hyperparamters of the classifier. \nparam_grid = {\n    'rf__n_estimators': [20, 50, 100, 150],\n    'rf__max_depth': [4, 5, 6, 7, 8],\n    'rf__criterion': ['gini', 'entropy']\n}\ngrid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, scoring='f1')\n\n# Fit the pipeline to the training data.\ngrid.fit(X_train, y_train)\nbest_params = grid.best_params_\n\n# Predict the dependent variable of the test set.\ny_pred = grid.predict(X_test)\n\n# Print the f1_score of the prediction.\nprint(\"f1_score\", round(f1_score(y_test, y_pred, average='binary'), 3))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### QUESTION 3\n\nThe next part is to create a version of the classifier that uses identified clusters.  Here is a class to get you started.  It is a transformer like those that we have been working with.  There is an example of how to use it just below.  In this example 4 clusters were specified and their one-hot encoded versions were appended to the feature matrix.  Now using pipelines and/or functions compare the performance using cluster profiling as part of your matrix to the baseline.  You may compare multiple models and multiple clustering algorithms here."
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "(750, 4)\n(750, 5)\n(750, 4)\n(750, 8)\n"
                }
            ],
            "source": "class KmeansTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, n_clusters=4):\n        self.n_clusters = n_clusters\n        self.km = KMeans(n_clusters=self.n_clusters, n_init=20)\n        \n    def transform(self, X, *_):\n        labels = self.km.predict(X)\n        return np.hstack((X, labels.reshape(-1, 1)))\n\n    def fit(self, X, y=None, *_):\n        self.km.fit(X)\n        labels = self.km.predict(X)\n        self.silhouette_score = round(silhouette_score(X, labels, metric='mahalanobis'), 3)\n        return self\n\nclass GmmTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, n_clusters=4):\n        self.n_clusters = n_clusters\n        self.gmm = BayesianGaussianMixture(n_components=self.n_clusters, covariance_type='full',\n                                           max_iter=500, n_init=10, warm_start=True)        \n    def transform(self, X,*_):\n        probs = self.gmm.predict_proba(X) + np.finfo(float).eps\n        return np.hstack((X, probs))\n        \n    def fit(self, X, y=None, *_):\n        self.gmm.fit(X)\n        labels = self.gmm.predict(X)\n        self.silhouette_score = round(silhouette_score(X, labels, metric='mahalanobis'), 3)\n        return self\n    \n\n    \n## example for kmeans\npreprocessor.fit(X_train)\nX_train_pre = preprocessor.transform(X_train)    \nkt = KmeansTransformer(4)\nkt.fit(X_train_pre)\nX_train_kmeans = kt.transform(X_train_pre)\nprint(X_train_pre.shape)\nprint(X_train_kmeans.shape)   \n    \n## example for GMM  \npreprocessor.fit(X_train)\nX_train_pre = preprocessor.transform(X_train)    \ngt = GmmTransformer(4)\ngt.fit(X_train_pre)\nX_train_gmm = gt.transform(X_train_pre)\nprint(X_train_pre.shape)  \nprint(X_train_gmm.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>kmeans</th>\n      <th>gmm</th>\n    </tr>\n    <tr>\n      <th>n_clusters</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0.633</td>\n      <td>0.604</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.583</td>\n      <td>0.595</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.603</td>\n      <td>0.583</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.592</td>\n      <td>0.592</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.496</td>\n      <td>0.605</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "            kmeans    gmm\nn_clusters               \n3            0.633  0.604\n4            0.583  0.595\n5            0.603  0.583\n6            0.592  0.592\n7            0.496  0.605"
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "## YOUR CODE HERE (Replace the #<> symbols by your code)\n\ndef run_clustering_pipeline(umodel):\n    \"\"\"\n    This function evaluates different Pipelines comprised of the preprocessing transfomer,\n    a clustering transformer and a classifier estimator.\n    INPUT : The name of the clustering transformer : 'gmm' or 'kmeans'\n    OUTPUT : The list of f1_scores of the pipeline on the test set for the different number of clusters\n    \"\"\"\n    \n    \n    fscores= [] # this list will store the f1_score of the different models that we will train\n    for n_clusters in np.arange(3, 8):\n\n        # Create an instance of a binary classifier (The same as the one you trained in the previous question)\n        estimator = RandomForestClassifier()\n        param_grid = {\n                        'n_estimators': [20, 50, 100, 150],\n                        'max_depth': [4, 5, 6, 7, 8],\n                        'criterion': ['gini', 'entropy']\n                    }\n        clf = GridSearchCV(estimator, param_grid=param_grid, cv=3, n_jobs=-1, scoring='f1')\n        \n        if umodel == 'gmm':\n            # Create an instance of the Gmm transformer with n_clusters clusters\n            cluster = GmmTransformer(n_clusters)    \n        elif umodel == 'kmeans':\n            # Create an instance of the Kmean transformer with n_clusters clusters\n            cluster = KmeansTransformer(n_clusters)\n        else:\n            raise Exception(\"invalid unsupervised learning model\")\n        \n        # Create a Pipeline that binds the preprocessing transformer, the clustering transformer and the classifier estimator\n        pipe =  Pipeline(steps=[('pre', preprocessor),\n                               ('clustering', cluster),\n                               ('classifier', clf)]) \n        \n        # Fit the pipeline on training set\n        pipe.fit(X_train, y_train)\n        # Predict the test set\n        y_pred = pipe.predict(X_test)\n        \n        # Compute the f1 score and add this score to the fscores list.\n        score = round(f1_score(y_test, y_pred, average='binary'), 3)\n        fscores.append(score)\n        \n    return fscores\n\n## run the different iteration of the model\ncp_results = {}\ncp_results['kmeans'] = run_clustering_pipeline('kmeans')\ncp_results['gmm'] = run_clustering_pipeline('gmm')\n\n## display table of results\ndf_cp = pd.DataFrame(cp_results)\ndf_cp[\"n_clusters\"] = [str(i) for i in np.arange(3,8)]\ndf_cp.set_index(\"n_clusters\", inplace=True)\ndf_cp.head(n=10)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## QUESTION 4\n\nRun an experiment to see if you can you improve on your workflow with the addition of re-sampling techniques? For instance, you can copy the structure of the function created in the previous question and add a re-sampling transformer to the pipeline."
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>kmeans</th>\n      <th>gmm</th>\n    </tr>\n    <tr>\n      <th>n_clusters</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0.615</td>\n      <td>0.636</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.599</td>\n      <td>0.596</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.621</td>\n      <td>0.600</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.599</td>\n      <td>0.636</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.611</td>\n      <td>0.612</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "            kmeans    gmm\nn_clusters               \n3            0.615  0.636\n4            0.599  0.596\n5            0.621  0.600\n6            0.599  0.636\n7            0.611  0.612"
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "## YOUR CODE HERE\n# This cell might take several minutes to run\n\ndef run_clustering_pipeline(umodel):\n    \"\"\"\n    This function evaluates different Pipelines constituated of the preprocessing transfomer,\n    a clustering transformer, a re-sampling transformer and a classifier estimator.\n    INPUT : The name of the clustering transformer : 'gmm' or 'kmeans'\n    OUTPUT : The list of f1_scores of the pipeline on the test set for the different number of clusters.\n    \"\"\"\n    \n    fscores = []  # this list will store the f1_score of the different models that we will train\n    for n_clusters in np.arange(3,8):\n        \n        # Create an instance of a binary classifier (The same as the one you trained in the previous question)\n        estimator = RandomForestClassifier()\n        param_grid = {\n                    'n_estimators': [20, 50, 100, 150],\n                    'max_depth': [4, 5, 6, 7, 8],\n                    'criterion': ['gini', 'entropy']\n                    }\n        clf = GridSearchCV(estimator, param_grid=param_grid, cv=3, n_jobs=-1, scoring='f1')\n        \n        if umodel == 'gmm':\n            # Create an instance of the Gmm transformer with n_clusters clusters\n            cluster = GmmTransformer(n_clusters)    \n        elif umodel == 'kmeans':\n            # Create an instance of the Kmean transformer with n_clusters clusters\n            cluster = KmeansTransformer(n_clusters)\n        else:\n            raise Exception(\"invalid unsupervised learning model\")\n            \n        \n        # Create a Pipeline that binds the preprocessing transformer, the clustering transformer, \n        # the re-sampling transformer and the classifier\n        pipe = pl.Pipeline(steps=[('pre', preprocessor),\n                                  ('clustering', cluster),\n                                  ('smote', SMOTE(random_state=42)),\n                                  ('classifier', clf)])  \n           \n        # Fit the pipeline on training set\n        pipe.fit(X_train,y_train) \n        # Predict the test set\n        y_pred = pipe.predict(X_test)  \n        # Compute the f1 score and add this score to the fscores list.\n        score = round(f1_score(y_test, y_pred,average='binary'),3)\n        fscores.append(score)\n        \n    return(fscores)\n\n## Run the different iteration of the model\ncp_results = {}\ncp_results['kmeans'] = run_clustering_pipeline('kmeans')\ncp_results['gmm'] = run_clustering_pipeline('gmm')\n\n\n## Display table of results\ndf_cp = pd.DataFrame(cp_results)\ndf_cp[\"n_clusters\"] = [str(i) for i in np.arange(3,8)]\ndf_cp.set_index(\"n_clusters\",inplace=True)\ndf_cp.head(n=10)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Usando Smote y atributos generados mediante Clustering, se logr\u00f3 mejorar los resultados."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}