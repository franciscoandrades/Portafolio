{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JXuCgXllujs"
   },
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/ISOTIPO-Color.jpg\" title=\"Title text\" width=\"20%\" />\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<H1 align='center'> Sistemas Recomendadores </H1>\n",
    "\n",
    "<H3> INF-479 Reconocimiento de patrones en Minería de Datos (Posgrado) </H3>\n",
    "<H3> Autores: Francisco Andrades | Lucas Díaz</H3>\n",
    "\n",
    "Lenguaje: Python\n",
    "\n",
    "Temas:\n",
    "\n",
    "    - Recomendación Basada en Usuarios (UBCF)\n",
    "    - Recomendación Basada en Items (IBCF)\n",
    "<hr style=\"height:2px;border:none\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d-grKSMElujv"
   },
   "outputs": [],
   "source": [
    "#Librerías \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7RsuC8ulujw"
   },
   "source": [
    "## Datasets Tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBebhzaclujw"
   },
   "source": [
    "Para la tarea tendrán a su disposición los siguientes 3 datasets, <b> de las cuales tendrán que escoger 2 para realizar la implementación de su tarea. </b>\n",
    "\n",
    "   ### 1. MovieLens: \n",
    "   Es uno de los datasets más populares de recomendación y recopila las preferencias de usuarios de internet con respecto a películas que son evaluadas de 0 a 5 estrellas. Este dataset ha sido utilizado en diversos estudios de investigación en áreas como la recomendación personalizada y la psicología social.  \n",
    "* <b>Archivos: </b>\n",
    "    - ML_ratings.csv: contiene los ratings dados por usuarios a películas. Se compone por las columnas user_id, movie_id y rating. \n",
    "    - movies.csv: contiene la metadata sobre las películas. Incluye las columnas movie_id, title y genres (donde se encuentran los géneros de la película separados por \"|\"). \n",
    " \n",
    "* <b>Cantidad de ratings</b>: 100836\n",
    "* <b>Cantidad de usuarios</b>: 610\n",
    "* <b>Cantidad de películas</b>: 9724\n",
    "* <b>Calificación</b> 0 a 5 (valores enteros) \n",
    "\n",
    "Referencias: [Movielens Dataset](https://grouplens.org/datasets/movielens/) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VezQWEFglujx"
   },
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv(\"ML_ratings.csv\")\n",
    "attr_df_movies = pd.read_csv(\"movies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50mOAsZllujz"
   },
   "source": [
    "### 2. Book-Crossing: \n",
    "Es un datasets de ratings de libros recolectado por Cai-Nicolas Ziegler desde la <i>Book-Crossing community</i>. El dataset original contiene 1,149,780 ratings generados por 278,858 usuarios a 271,379 libros. \n",
    "\n",
    "* <b>Archivos</b>: \n",
    "    - BX_ratings.csv: contiene los ratings dados por usuarios a diferentes libros. Se compone de las columnas user_id, ISBN (identificador para los libros) y rating.\n",
    "    - books.csv: contiene los títulos de libros asociados a los códigos ISBN (utilizados como item_id). Se compone de las columnas ISBN y title. \n",
    "\n",
    "* <b>Cantidad de ratings</b>: 359263\n",
    "* <b>Cantidad de usuarios</b>: 10775\n",
    "* <b>Cantidad de libros</b>: 10773\n",
    "* <b>Calificación</b>: 0 a 10 (valores enteros)\n",
    "\n",
    "Referencias: [Book-Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "usU2Gvw7lujz"
   },
   "outputs": [],
   "source": [
    "df_books = pd.read_csv(\"BX_ratings.csv\")\n",
    "attr_df_books = pd.read_csv(\"books.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8M0kOgfHluj0"
   },
   "source": [
    "### 3. Jester: \n",
    "Es un dataset desarrollado por Ken Goldberg y su equipo en la Universidad de Berkeley, el cual contiene alrededor de 6 millones de ratings con respecto a 150 chistes cortos. \n",
    "* <b>Archivos</b>:\n",
    "    - JT_ratings.csv: contiene los ratings dados por usuarios a diferentes chistes cortos. Se compone por las columnas joke_id, user_id y rating. \n",
    "    - jokes.csv: contiene \n",
    "\n",
    "* <b>Cantidad de ratings</b>: 199900\n",
    "* <b>Cantidad de usuarios</b>: 1999\n",
    "* <b>Cantidad de chistes</b>: 100 \n",
    "* <b>Calificación</b>: -10 a 10 (valores reales)\n",
    "    \n",
    "Referencias: [Jester Dataset](http://eigentaste.berkeley.edu/dataset/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "H5cb3OuTluj0"
   },
   "outputs": [],
   "source": [
    "df_jokes = pd.read_csv(\"JT_ratings.csv\")\n",
    "attr_df_jokes = pd.read_csv(\"jokes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80fj3WACluj0"
   },
   "source": [
    "## Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41huF8KNluj1"
   },
   "source": [
    "<img src=\"https://media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs11227-020-03266-2/MediaObjects/11227_2020_3266_Fig1_HTML.png\" title=\"Title text\" width=\"60%\" />\n",
    "<center> <i> Figura 1. Collaborative Filtering. </i> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvCV_-P_rZcO"
   },
   "source": [
    "Las recomendaciones obtenidas se obtuvieron cuando en la función interfaz el parámetro custom=False. Para calificar items por consola, debe setearse custom=True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pbPLCJqluj1"
   },
   "source": [
    "## 1. User based Collaborative Filtering (40 puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2I-hlAKluj1"
   },
   "source": [
    "La primera parte de la tarea constará de las siguientes secciones: \n",
    "1. Implementación de un sistema de recomendación de filtro colaborativo basado en usuarios utilizando los k vecinos más cercanos. Para esta parte, se debe utilizar <b> similaridad coseno </b> como medida de similaridad entre el usuario objetivo y el resto de usuarios. Además, el parámetro k debe ser escogido por ustedes. \n",
    "\n",
    "2. Se ingresa nuevo usuario al sistema, se le pide que califique 10 productos (a elección) y a partir de eso se le realiza la recomendación de 5 productos que no ha calificado. Es importante que en su procedimiento se muestren las ids de los k vecinos más cercanos.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "TElS0yUZqCt7",
    "outputId": "a115cc26-d3bb-406b-be50-abbd712ec42b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para Movies: \n",
      "Usuarios mÃ¡s cercanos:  [6, 501, 43, 414, 84, 117, 170, 470, 68, 458]\n",
      "[356 457 377 480 318]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ISBN, title]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para Jokes:\n",
      "Usuarios mÃ¡s cercanos:  [1730, 512, 502, 350, 1478, 1033, 106, 1563]\n",
      "[65 48 10 41 52]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke_id</th>\n",
       "      <th>joke_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>A lawyer opened the door of his BMW, when sudd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Three engineering students were gathered toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Q. What do a hurricane, a tornado, and a redne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>Two men are discussing the age old question: w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>One Sunday morning William burst into the livi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    joke_id                                          joke_text\n",
       "65       65  A lawyer opened the door of his BMW, when sudd...\n",
       "48       48  Three engineering students were gathered toget...\n",
       "10       10  Q. What do a hurricane, a tornado, and a redne...\n",
       "41       41  Two men are discussing the age old question: w...\n",
       "52       52  One Sunday morning William burst into the livi..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def calcular_neighbours(df_useritem, user_u,k):\n",
    "    df_useritem = df_useritem.copy()\n",
    "    df_useritem = df_useritem.fillna(0)\n",
    "\n",
    "    user_u2 = user_u[np.logical_not(np.isnan(user_u))]\n",
    "    similarities = []\n",
    "    for cont in range(df_useritem.shape[0]):\n",
    "        user_v = df_useritem.iloc[cont].values\n",
    "        user_v = user_v[np.logical_not(np.isnan(user_u))]\n",
    "        user_v = np.array(user_v.reshape(1,-1),dtype=object)\n",
    "        similarities.append((cont,cosine_similarity(user_u2.reshape(1,-1), user_v)[0][0]))\n",
    "\n",
    "    similaridades = sorted(similarities, key=lambda tup: tup[1])[::-1]\n",
    "    df_return = df_useritem.iloc[np.array(similaridades[:k], dtype=object)[:,0]]\n",
    "    df_return = df_return.sub(df_return.mean(axis=1), axis=0)\n",
    "    df_return['similaridad'] = np.array(similaridades[:k], dtype=object)[:,1]\n",
    "    return df_return\n",
    "\n",
    "\n",
    "def recomendaciones(array_usuario,df_pivot,k,imprimir):\n",
    "    array_usuario = array_usuario.copy()\n",
    "    similaridades = calcular_neighbours(df_pivot,array_usuario,k)\n",
    "    if imprimir:\n",
    "        print(\"Usuarios más cercanos: \",list(similaridades.index))\n",
    "    mask = np.isnan(array_usuario)\n",
    "    completar = np.argwhere(mask)\n",
    "    sim = similaridades['similaridad'].values\n",
    "    media_usuario = np.mean(array_usuario[np.logical_not(mask)])\n",
    "    lista = []\n",
    "    for indice in completar:\n",
    "        # SE TIENE VALUES RATINGS PELICULA Y VALUES SIMILARIDADES\n",
    "        #CALCULAR CON LA FORMULA RATING \n",
    "        columna = similaridades.iloc[:,indice].values\n",
    "        valores = columna.squeeze()*sim\n",
    "        suma = np.sum(valores)\n",
    "        delta = suma/np.sum(sim)\n",
    "        lista.append((indice[0],(media_usuario+delta)))\n",
    "    ratings = sorted(lista, key=lambda tup: tup[1])[::-1]\n",
    "    recomendar = np.array(ratings)[:5,0]\n",
    "    id_peliculas = np.array(df_pivot.columns)[recomendar.astype(int)]\n",
    "    return np.array([elem[1] for elem in id_peliculas])\n",
    "\n",
    "\n",
    "def recomendar(df_pivot,array_usuario,k,imprimir=True):\n",
    "    predicciones = recomendaciones(array_usuario,df_pivot,k,imprimir)\n",
    "    return predicciones\n",
    "\n",
    "def get_items(attr_df, ordenada2):\n",
    "    \n",
    "    retorno = attr_df[attr_df.iloc[:, 0] == ordenada2[0]]\n",
    "    retorno = retorno.append(attr_df[attr_df.iloc[:, 0] == ordenada2[1]])\n",
    "    retorno = retorno.append(attr_df[attr_df.iloc[:, 0] == ordenada2[2]])\n",
    "    retorno = retorno.append(attr_df[attr_df.iloc[:, 0] == ordenada2[3]])\n",
    "    retorno = retorno.append(attr_df[attr_df.iloc[:, 0] == ordenada2[4]])\n",
    "    \n",
    "    return retorno\n",
    "\n",
    "def interfaz(df,df_map,k,custom = False):\n",
    "    df_pivot = df.pivot_table(index = df.user_id, columns = df.columns[df.columns != \"user_id\"][0])\n",
    "    array_usuario = np.full(df_pivot.shape[1],np.nan)\n",
    "    if custom is False:\n",
    "        array_usuario[:10] = [1,2,3,4,5,1,2,3,4,5]\n",
    "        recomendados = recomendar(df_pivot,array_usuario,k)\n",
    "        print(recomendados)\n",
    "        items = get_items(df_map,recomendados)\n",
    "        return items\n",
    "    ids = df_pivot.columns.get_level_values(1)\n",
    "    sample = np.random.choice(ids.shape[0],10,replace=False)\n",
    "    for cont in sample:\n",
    "        array_usuario[cont] = input(\"Califica el item: \"+str(ids[cont])+' ')\n",
    "    \n",
    "    recomendados = recomendar(df_pivot,array_usuario,k)\n",
    "    items = get_items(df_map,recomendados)\n",
    "    return items\n",
    "\n",
    "def analisis(df):\n",
    "    df_pivot = df.pivot_table(index = df.user_id, columns = df.columns[df.columns != \"user_id\"][0])\n",
    "    array_usuario = np.full(df_pivot.shape[1],np.nan)\n",
    "    array_usuario[:10] = [1,2,3,4,5,1,2,3,4,5]  \n",
    "    predicciones = [recomendar(df_pivot,array_usuario,i,False) for i in range(1,20,1)]\n",
    "    estadistica = []\n",
    "    unique=[]\n",
    "    for i in range(len(predicciones)):\n",
    "        cont = 0\n",
    "        for elem in predicciones[i]:\n",
    "            if elem not in unique:\n",
    "                unique.append(elem)\n",
    "                cont += 1\n",
    "        if len(unique) > 10:\n",
    "            unique = unique[-10:]\n",
    "        estadistica.append(6-cont)\n",
    "    plt.bar(range(len(estadistica)),estadistica)\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "print(\"Para Movies: \")\n",
    "preds_movies = interfaz(df_movies, attr_df_books,10, custom=False)\n",
    "display(preds_movies)\n",
    "\n",
    "print(\"Para Jokes:\")\n",
    "preds_jokes = interfaz(df_jokes, attr_df_jokes, 8, custom=False)\n",
    "display(preds_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Udltx7Zz8YB4",
    "outputId": "cdd49815-0ef4-4e2f-a09d-68ebe52b1163"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Celda demora 5 min aprox\n",
    "analisis(df_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "B8zRgWQm-Vaf",
    "outputId": "4762542e-95b1-46d2-a1ab-66fc07766161"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analisis(df_jokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOnc37mc8bSq"
   },
   "source": [
    "#### Análisis\n",
    "\n",
    "Los gráficos muestran lo siguiente:\n",
    "\n",
    "Para cada k in $range(1,20)$:\n",
    "    \n",
    "$$6 - R_k$$\n",
    "\n",
    "Donde,\n",
    "\n",
    "$R_k$: Cantidad de items recomendados **que no se han visto nunca para todos los $k_{anteriores} < k$** (con una memoria que sólo incluye los últimos 10 items únicos vistos).\n",
    "\n",
    "No se ocupa $R_k$ directamente para una mejor visualización.\n",
    "Mientras más alta la estadística, más \"estable\" son las recomendaciones (no se están proponiendo recomendaciones nuevas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KvRM87x98jy4",
    "outputId": "adf144f2-6985-43c4-d15b-2faf07d798fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity para jokes: % 0.0\n",
      "Sparsity para movies: % 98.30003169443864\n"
     ]
    }
   ],
   "source": [
    "df_pivotaux = df_jokes.pivot_table(index = df_jokes.user_id, columns = df_jokes.columns[df_jokes.columns != \"user_id\"][0])\n",
    "print(\"Sparsity para jokes: %\", df_pivotaux.isna().sum().sum()/(df_pivotaux.shape[0]*df_pivotaux.shape[1]))\n",
    "df_pivotaux = df_movies.pivot_table(index = df_movies.user_id, columns = df_movies.columns[df_movies.columns != \"user_id\"][0])\n",
    "print(\"Sparsity para movies: %\", df_pivotaux.isna().sum().sum()/(df_pivotaux.shape[0]*df_pivotaux.shape[1])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7BM3ltc8f94"
   },
   "source": [
    "### Para Movies\n",
    "3. Concluir y responder las siguientes preguntas: \n",
    "\n",
    "   >a. ¿Cuáles fueron las 5 recomendaciones obtenidas? Analice y concluya respecto a estos resultados.  \n",
    "    * Se recomendaron las películas: Forrest Gump (1994), Fugitive, The (1993), Speed (1994), Jurassic Park (1993), Shawshank Redemption, The (1994). Se aprecia una similaridad en los géneros y en las películas (Grandes películas).\n",
    "    \n",
    "   >b. ¿Qué cantidad de vecinos cercanos (k) se escogió para la recomendación? ¿En qué influye la elección de este parámetro? ¿Qué sucede a medida que aumenta este parámetro? \n",
    "   * Se escogió k = 10, observando el análisis propuesto. Se puede apreciar que la elección de este parámetro afecta de manera significativa cuando k es pequeño y de forma menos relavante a medida que k aumenta.\n",
    "   A medida que el parámetro aumenta se \"estabiliza\" la recomendación. La recomendación utilizando (k+n) vecinos tiende a ser igual a la recomendación utilizando k vecinos cuando k >> n.\n",
    "    \n",
    "   >c. ¿Cuál era el porcentaje de <i>sparsity</i> de la matriz usuarios-items? ¿Cuáles son las desventajas de este enfoque? \n",
    "   * 98% de sparsity (98% de los valores son missing values). La desventaja de este enfoque frente a IBCF es la escalabilidad cuando usuarios >> items, que es el caso más común (Dataset Jokes). Para cada usuario nuevo, se debe computar la similaridad con el resto de usuarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwh7pPtM8tIk"
   },
   "source": [
    "### Para Jokes\n",
    "3. Concluir y responder las siguientes preguntas: \n",
    "\n",
    "   >a. ¿Cuáles fueron las 5 recomendaciones obtenidas? Analice y concluya respecto a estos resultados.  \n",
    "    * Se recomendaron los chistes: Se recomendaron los chistes: 65, 48, 10, 41, 52.\n",
    "    \n",
    "   >b. ¿Qué cantidad de vecinos cercanos (k) se escogió para la recomendación? ¿En qué influye la elección de este parámetro? ¿Qué sucede a medida que aumenta este parámetro? \n",
    "   * Se escogió k = 8, observando el análisis propuesto. Se puede apreciar que la elección de este parámetro afecta de manera significativa cuando k es pequeño y de forma menos relavante a medida que k aumenta.\n",
    "   A medida que el parámetro aumenta se \"estabiliza\" la recomendación. La recomendación utilizando (k+n) vecinos tiende a ser igual a la recomendación utilizando k vecinos cuando k >> n.\n",
    "    \n",
    "     >c. ¿Cuál era el porcentaje de <i>sparsity</i> de la matriz usuarios-items? ¿Cuáles son las desventajas de este enfoque? \n",
    "     * 0% de sparsity (0% de los valores son missing values). La desventaja de este enfoque frente a IBCF es la escalabilidad cuando usuarios >> items, que es el caso más común (Dataset Jokes). Para cada usuario nuevo, se debe computar la similaridad con el resto de usuarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeZw3_CEluj2"
   },
   "source": [
    "## 2. Item based Collaborative Filtering (40 puntos) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxV9mLT5luj2"
   },
   "source": [
    "La segunda parte de la tarea constará de las siguientes secciones: \n",
    "1. Implementación de un sistema de recomendación de filtro colaborativo basado en ítems utilizando los k ítems más cercanos. Para esta parte, se debe utilizar <b> similaridad coseno </b> como medida de similaridad entre los ítems. Además, el parámetro k debe ser escogido por ustedes. \n",
    "\n",
    "2. Se ingresa nuevo usuario al sistema, se le pide que califique 10 productos (a elección) y a partir de eso se le realiza la recomendación de 5 productos que no ha calificado. Para poder llevar a cabo la recomendación recordar los siguientes pasos:\n",
    "    >a. Se debe generar la matriz de similaridad entre productos basada en la similaridad coseno.\n",
    "    \n",
    "    >b. Para realizar la recomendación, se debe predecir el rating de todos los productos que el usuario nuevo del sistema no haya calificado aún. Para esto, se deben obtener los k ítems más cercanos al ítem a predecir y se debe predecir su rating en base a la <i> weighted sum </i> de los ratings de dichos k ítems. \n",
    "    \n",
    "    >c. Una vez predecidos los ratings para todos los productos sin calificación, se deben recomendar al usuario los 5 productos con mayor rating predecido. \n",
    "\n",
    "\n",
    "<i>Importante: Esto debe ser realizado para ambos datasets escogidos</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "klfbzzNJ5naX"
   },
   "outputs": [],
   "source": [
    "#SOLO CORRER UNA VEZ ESTA CELDA -> VENTAJA DE IBCF B)\n",
    "def item_matrix_similarity(df):\n",
    "    df_itemuser = df.copy()\n",
    "    df_itemuser = df_itemuser.fillna(0)\n",
    "\n",
    "    return pd.DataFrame(cosine_similarity(df_itemuser))\n",
    "\n",
    "ITMS_movies = item_matrix_similarity(df_movies.pivot_table(index=df_movies.movie_id, columns=df_movies.user_id))\n",
    "ITMS_jokes = item_matrix_similarity(df_jokes.pivot_table(index=df_jokes.joke_id, columns=df_jokes.user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "36g6ZcK4ZF7-"
   },
   "outputs": [],
   "source": [
    "def recomendacion(df_pivot, lista_retorno, verbose=False):\n",
    "    \"\"\"\n",
    "    df_pivot     : dataframe pivoteado \n",
    "    lista_retorno: lista con todas las predicciones de items no vistos por u\n",
    "                   (posición_del_item, predicción)\n",
    "    \"\"\"\n",
    "    #se ordena lista de predicciones y se obtienen las con 5 mejores ratings\n",
    "    ordenada = sorted(lista_retorno, key = lambda x: x[1])[-5:]\n",
    "    if verbose:\n",
    "        print(\"Ordenada1: \", ordenada)\n",
    "    ordenada2 = df_pivot.index[np.array(ordenada)[:, 0].astype(int)]\n",
    "    if verbose:\n",
    "        print(\"Ordenada2: \", ordenada2)\n",
    "    ordenada2 = ordenada2.get_level_values(0).values\n",
    "    return ordenada2\n",
    "\n",
    "def get_items(attr_df, ordenada2):\n",
    "    \"\"\"\n",
    "    attr_df  : dataframe con info de los items (ej: movies.csv o jokes.csv)\n",
    "    ordenada2: ids de los 5 items a recomendar\n",
    "    \"\"\"\n",
    "    retorno = attr_df[attr_df.iloc[:, 0] == ordenada2[4]]\n",
    "    retorno = retorno.append(attr_df[attr_df.iloc[:, 0] == ordenada2[3]])\n",
    "    retorno = retorno.append(attr_df[attr_df.iloc[:, 0] == ordenada2[2]])\n",
    "    retorno = retorno.append(attr_df[attr_df.iloc[:, 0] == ordenada2[1]])\n",
    "    retorno = retorno.append(attr_df[attr_df.iloc[:, 0] == ordenada2[0]])\n",
    "\n",
    "    return retorno\n",
    "\n",
    "def item_calcular(df, itms, k):\n",
    "    \"\"\"\n",
    "    df  : dataframe pivoteado item-user\n",
    "    itms: matriz similaridad para items de df\n",
    "    k   : vecinos cercanos\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    u_itemsvistos = np.array([cont for cont in range(df.shape[0]) if df.iloc[cont, -1] != 0])\n",
    "\n",
    "    lista_retorno = []\n",
    "    i = 0\n",
    "    for cont in range(df.shape[0]): # recorre rows dataframe items-users\n",
    "        item_j = df.iloc[cont] # item j en row numero cont\n",
    "        if item_j.values[-1] == 0: # ese item fue visto por u? si no fue visto, entra\n",
    "            \n",
    "            item_i = itms.iloc[cont].values # se obtiene row de similaridad del item j con todos los demás\n",
    "            #similaridades = [item_i[index] for index in u_itemsvistos] #(filtro) similaridad item j con items vistos por user u\n",
    "            similaridades = item_i[u_itemsvistos]\n",
    "            \n",
    "            info = list(zip(u_itemsvistos, similaridades)) #(id_item, similaridad)\n",
    "            k_vecinos = sorted(info, key = lambda x: x[1])[-k:] #(id_item, similaridad) ordenado por similaridad (x[1])\n",
    "\n",
    "            item_indexes = list(zip(*k_vecinos))[0] # ids_items\n",
    "            similarities = list(zip(*k_vecinos))[1] # similaridades\n",
    "\n",
    "            #cálculo predicción\n",
    "            num = np.sum(similarities * df['user_u'].iloc[list(item_indexes)].values)\n",
    "            denom = np.sum(similarities)\n",
    "            \n",
    "            #if np.isnan(rating_prediccion) or np.any(np.isclose(similarities, 0)):\n",
    "            if denom == 0 or np.any(np.isclose(similarities, 0)):\n",
    "                lista_retorno.append((cont, -1))\n",
    "                continue\n",
    "            \n",
    "            rating_prediccion = num/denom\n",
    "            lista_retorno.append((cont, rating_prediccion))\n",
    "\n",
    "    return lista_retorno\n",
    "\n",
    "def ibcf(df_pivot, array_usuario, k, itms):\n",
    "\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    #itms = item_matrix_similarity(df_pivot)\n",
    "\n",
    "    df_pivot['user_u'] = array_usuario\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "\n",
    "    #return get_items(attr_df, recomendacion(df_pivot, item_calcular(df_pivot, itms, k)))\n",
    "    return recomendacion(df_pivot, item_calcular(df_pivot, itms, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9dNYDTsnI73i"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def interfaz(df, df_map, k, itms, custom = False):\n",
    "    df = df.rename(columns={\"movie_id\": \"item_id\", \"joke_id\": \"item_id\"})\n",
    "    df_map = df_map.rename(columns={\"movie_id\": \"item_id\", \"joke_id\": \"item_id\"})\n",
    "\n",
    "    df_pivot = df.pivot_table(columns = df.user_id, index = df.item_id)\n",
    "    array_usuario = np.full(df_pivot.shape[0], np.nan)\n",
    "    if custom is False:\n",
    "        array_usuario[:10] = [1,2,3,4,5,1,2,3,4,5]\n",
    "        recomendados = ibcf(df_pivot, array_usuario, k, itms)\n",
    "        items = get_items(df_map, recomendados)\n",
    "        return items\n",
    "    ids = df_pivot.index.get_level_values(0)\n",
    "    sample = np.random.choice(ids.shape[0], 10, replace=False)\n",
    "    for cont in sample:\n",
    "        array_usuario[cont] = input(\"Califica el item: \"+str(ids[cont])+' ')\n",
    "    \n",
    "    recomendados = ibcf(df_pivot, array_usuario, k, itms)\n",
    "    items = get_items(df_map, recomendados)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "z1RqpFgDuSG1",
    "outputId": "af75881f-1480-4410-e783-ba4b746a7a06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>joke_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Q. What is orange and sounds like a parrot?  \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>How many teddybears does it take to change a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>What do you get when you run over a parakeet w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>How many men does it take to screw in a light ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>A horse walks into a bar. Bartender says:\\n\"So...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    item_id                                          joke_text\n",
       "15       15  Q. What is orange and sounds like a parrot?  \\...\n",
       "57       57  How many teddybears does it take to change a l...\n",
       "23       23  What do you get when you run over a parakeet w...\n",
       "16       16  How many men does it take to screw in a light ...\n",
       "43       43  A horse walks into a bar. Bartender says:\\n\"So..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interfaz(df_jokes, attr_df_jokes, 9, ITMS_jokes, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "id": "Q_wXQbfksifn",
    "outputId": "e7c69ef9-8e00-4647-c491-2bfef0ae314d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>113</td>\n",
       "      <td>Before and After (1996)</td>\n",
       "      <td>Drama|Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>195</td>\n",
       "      <td>Something to Talk About (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>61</td>\n",
       "      <td>Eye for an Eye (1996)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>747</td>\n",
       "      <td>Stupids, The (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>381</td>\n",
       "      <td>When a Man Loves a Woman (1994)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_id                            title                genres\n",
       "100      113          Before and After (1996)         Drama|Mystery\n",
       "165      195   Something to Talk About (1995)  Comedy|Drama|Romance\n",
       "54        61            Eye for an Eye (1996)        Drama|Thriller\n",
       "600      747              Stupids, The (1996)                Comedy\n",
       "338      381  When a Man Loves a Woman (1994)         Drama|Romance"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interfaz(df_movies, attr_df_movies, 9, ITMS_movies, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "WqhPPAqQJ5uR",
    "outputId": "a0efa5e8-fa50-49a8-d375-83117154b429"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analisis(df, itms):\n",
    "    df_pivot = df.pivot_table(columns = df.user_id, index = df.columns[df.columns != \"user_id\"][0])\n",
    "    array_usuario = np.full(df_pivot.shape[0], np.nan)\n",
    "    array_usuario[:10] = [1,2,3,4,5,1,2,3,4,5]  \n",
    "    predicciones = [ibcf(df_pivot, array_usuario, i, itms) for i in range(1, 20, 1)]\n",
    "    estadistica = []\n",
    "    unique=[]\n",
    "    for i in range(len(predicciones)):\n",
    "        cont = 0\n",
    "        for elem in predicciones[i]:\n",
    "            if elem not in unique:\n",
    "                unique.append(elem)\n",
    "                cont += 1\n",
    "        if len(unique) > 10:\n",
    "            unique = unique[-10:]\n",
    "        estadistica.append(6-cont)\n",
    "\n",
    "    plt.bar(range(len(estadistica)),estadistica)\n",
    "    plt.show()\n",
    "    return 0\n",
    "\n",
    "analisis(df_jokes, ITMS_jokes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "0-DgSgC9pCXX",
    "outputId": "905c32dc-8c80-4264-9e41-0cd612537297"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Celda demora 5 min aprox\n",
    "analisis(df_movies, ITMS_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "an8TnWNix-am"
   },
   "source": [
    "# Dataset Jokes\n",
    "3. Concluir y responder las siguientes preguntas: \n",
    "\n",
    "   >a. ¿Cuáles fueron las 5 recomendaciones obtenidas? Analice y concluya respecto a estos resultados.  \n",
    "    * Joke_id = 15\n",
    "    * Joke_id = 57\n",
    "    * Joke_id = 23\n",
    "    * Joke_id = 16\n",
    "    * Joke_id = 43\n",
    "\n",
    "   >b. ¿Qué cantidad de vecinos cercanos (k) se escogió para la recomendación? ¿En qué influye la elección de este parámetro? ¿Qué sucede a medida que aumento este parámetro?\n",
    "    * Se escogieron k=9 vecinos cercanos. La influencia radica en que al cambiarlo la recomendación puede variar. A medida que el parámetro aumenta, las recomendaciones se van estabilizando, es decir, se van recomendando los mismos items. \n",
    "\n",
    "   >c. ¿Cuáles son las ventajas de este enfoque respecto al anterior?\n",
    "    * Si bien se necesita espacio para almacenar la matriz de similaridades, esto permite escalar de buena manera conforme aumentan los datos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00e2r0M9x3Ie"
   },
   "source": [
    "# Dataset Movies\n",
    "3. Concluir y responder las siguientes preguntas: \n",
    "\n",
    "   >a. ¿Cuáles fueron las 5 recomendaciones obtenidas? Analice y concluya respecto a estos resultados.  \n",
    "   * Before and after (1996).\n",
    "   * Something to talk about (1995).\n",
    "   * Eye for an eye (1996).\n",
    "   * Stupids, the (1996).\n",
    "   * When a man loves a woman (1994).\n",
    "\n",
    "   Todas las películas se asemejan según el(los) género(s) que pertenecen. Lo anterior, de forma directa o de manera transitiva. Además, las películas recomendadas son contemporáneas.\n",
    "    \n",
    "   >b. ¿Qué cantidad de vecinos cercanos (k) se escogió para la recomendación? ¿En qué influye la elección de este parámetro? ¿Qué sucede a medida que aumento este parámetro?\n",
    "    * Se escogieron k=9 vecinos cercanos. La influencia radica en que al cambiarlo la recomendación puede variar. A medida que el parámetro aumenta, las recomendaciones se van estabilizando, es decir, se van recomendando los mismos items. \n",
    "\n",
    "   >c. ¿Cuáles son las ventajas de este enfoque respecto al anterior?\n",
    "    * Si bien se necesita espacio para almacenar la matriz de similaridades, esto permite escalar de buena manera conforme aumentan la cantidad usuarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7HORS5Yluj2"
   },
   "source": [
    "## 3. Conclusiones finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuJt4Wy-luj3"
   },
   "source": [
    "1. Analice los resultados obtenidos y contraste ambos enfoques (ubcf y ibcf). \n",
    "\n",
    "* Es importante notar que los resultados obtenidos por cada método fueron distintos. Tomando esto en cuenta, sería interesante considerar un ensamblado que utilice ambos enfoques promediados para computar una recomendación final.\n",
    "\n",
    "2. Analice ventajas y desventajas de ambos enfoques. \n",
    "* En el caso más común, presente en el dataset Jokes, que es cuando la cantidad de usuarios >> cantidad items, el método IBCF demostró ser más eficiente, debido a que solo computa la matriz de similaridades 1 vez. Sin embargo, en el caso atípico donde la cantidad de usuarios << cantidad de items, presente en el dataset Movies, el método UBCF demostró ser más eficiente, debido a que IBCF debe hacer el cómputo de los vecinos más cercanos y el análisis posterior **para cada item faltante**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea 3 - INF 479.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
